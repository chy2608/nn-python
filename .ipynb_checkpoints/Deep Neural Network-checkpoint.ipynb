{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8290fae8-a8ce-4788-89d7-6f32a7db9ca8",
   "metadata": {},
   "source": [
    "# Using Python to Create a Deep Neural Network from Scratch\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This personal project aims to build a deep neural network from scratch using only python and numpy libraries. The goal of this project is to serve as a self-exercise into the field of machine learning to help myself understand the workings of a multi-layer perceptron better, and so the project begins with the mathematical side of DNN, such as forward and backpropogation. Further on in the project, multiprocessing is also employed to optimise runtimes, allowing the computer to calculate gradients for different instances at the same time. \n",
    "\n",
    "## Mathematics of DNN\n",
    "\n",
    "### Structure of a DNN\n",
    "\n",
    "The structure of a deep neural network consists of one input layer, a series of hidden layers, and one output layer. Each layer consists of numerous nodes, each node connecting to every other node in the previous and next layer. This allows for the formation of complex relationships between each node and thus extending to the entire network, allowing for it to \"learn\" patterns in data. \n",
    "\n",
    "<center><img src=\"./img/DNN.jpg\"/></center>\n",
    "\n",
    "In the above figure, we have a DNN with an architecture of 3-3-3-2:  3 input nodes, 2 hidden layers with 3 nodes each, and 2 output nodes. Each node has a corresponding layer number, $l$, and its position within the layer $j$, both of which follows zero-based indexing. With this, we can denote a node using $\\nu^{(l)}_j$. \n",
    "\n",
    "### Weights and Biases\n",
    "\n",
    "The intricate relationships that form between each node and layer and subsequently the entire network is based on the fact that each node's value is a linear combination of the values of every node of the previous layer. The coefficients of the values of the nodes of the previous layer are known as weights, and can be represented by the lines connecting the nodes in the above figure. For some node $\\nu^{(l)}_j$, and a node in the previous layer $\\nu^{(l-1)}_k$, we denote the weight connecting these two nodes to be $w^{(l)}_{jk}$.\n",
    "\n",
    "<center><img src=\"./img/Weights.jpg\"/></center>\n",
    "\n",
    "However, each node $\\nu^{(l)}_j$ also has a \"bias\" term corresponding to it, denoted as $b^{(l)}_j$, and so the value associated with each node $a^{(l)}_j$ is given by the sum\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "a^{(l)}_j = \\sigma \\left(\\sum_{k = 0}^{N(l-1)-1}w^{(l)}_{jk}\\cdot a^{(l-1)}_k + b^{(l)}_j\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $N(l-1)$ is the number of nodes in the layer $l-1$. Note that in front, there appears a function $\\sigma$ that wraps around the entire calculation. This is known as an activation function which processes the \"pure\" value of the node (the linear combination + bias) into an \"activated\" value. From now on, we denote the \"pure\" value of a node to be $z^{(l)}_j$ and its \"activated\" value to be $a^{(l)}_j$. Hence, we can see that the value of a node (both pure or activated) depends on the _activated_ values of the previous nodes. \n",
    "\n",
    "#### Activation Functions\n",
    "\n",
    "If all node values were kept as its \"pure\" value $z^{(l)}_j$, we would only ever have linear relationships between each node, and that would cause the neural network to be mathematically equivalent to having no hidden layers at all, and the network would only ever be able to learn linear patterns. However, in real life, many patterns are more complex than linear relationships, and so by passing the \"pure\" value through a non-linear function, we can allow the DNN to learn non-linear patterns. There are many activation functions, each suited for a different purpose. Some activation functions depend only on the $z^{(l)}_j$ of the node in question, such as the Rectified Linear Unit (ReLU):\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "a^{(l)}_j = \\sigma \\left( z^{(l)}_j \\right) = \n",
    "\\begin{cases}\n",
    "z^{(l)}_j, &z^{(l)}_j > 0 \\\\ \n",
    "0, &z^{(l)}_j \\leq 0\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "whereas some other activation functions depend on the $z^{(l)}_k$ of all nodes in the layer, such as the Softmax activation function:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "a^{(l)}_j = \\sigma \\left( z^{(l)}_j \\right) =  \\frac{\\exp{z^{(l)}_j}}{\\sum_{k = 0}^{N(l)-1}\\exp{z^{(l)}_k}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Forward Propagation and Loss\n",
    "\n",
    "For a specific set of input values, we can use the above equation to calculate the values of every node in the next layer, and using those values, calculate the values of the next layer so on and so forth, until we _propagate_ and calculate the values of the output layer. This process is known as forward propagation. \n",
    "\n",
    "During the training process, multiple pairs of inputs and labels (correct \"answers\") are used. For each pair, we pass the inputs through the DNN, and using forward propagation, we return with some outputs (predicted \"answers\") $a^{(L_f)}_j$ ($L_f$ is the final/output layer). We then compare the correct values $y_j$ and predicted values $a^{(L_f)}_j$, and measure how far off we are, or how wrong we are. To mathematically encapsulate the idea of \"wrongness\", we use what we call a Loss function $L(y_j, a^{(L_f)}_j)$. Using this Loss function, it tells us how far off we are from the correct answer, and depending on it, we can adjust the values of the weights and biases and try a different pair again. By repeating this process, we essentially end up tuning our DNN to be able to recognise the patterns of the input and output pairs.\n",
    "\n",
    "How the Loss function encapsulates \"wrongness\" depends on the type of Loss function itself. For example, in regression, squared loss is a common loss function, where we measure the total magnitude of the differences between the predicted and true values:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L = \\sum_{j = 0}^{N(L_f)-1}\\left(y_j - a^{(L_f)}_j\\right)^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Another loss function is known as Categorical Cross-Entropy, and is commonly used in cases where the output is separated into discrete classes:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L = \\sum_{j = 0}^{N(L_f)-1}\\left(-y_j \\cdot \\log a^{(L_f)}_j\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "There are many different types of loss functions, each suited for a different class of problems. There is no one-size-fits-all type of loss function. \n",
    "\n",
    "### Backpropagation \n",
    "\n",
    "Backpropagation refers to the process where the loss function is used to tune the weights and biases of the model to improve it. If we can find how a change in the weights/biases affects the loss (\"wrongness\"), we can update the weights and biases according to that to decrease the loss. How a change in the weights/biases affects the loss is exactly the derivative (more accurately, the partial derivative) of loss w.r.t the weights and biases:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial w^{(l)}_{jk}} \\qquad \\frac{\\partial L}{\\partial b^{(l)}_j}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "From multivariable calculus, we can use these partial derivatives to form a gradient vector field $\\nabla L$, which, for any input in the input space (in this case, a vector of all parameters $\\textbf{p}$) returns a vector of steepest ascent up the loss function. Hence, to minimise the loss function, we must move in the opposite direction to said vector, namely $-\\nabla L$ with some step-size $r$ known as the learning rate. So, we can form two equations that tell us how to update the $i$-th iteration weights and biases:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textbf w_{i+1} &= \\textbf w_i - r\\nabla L_w \\\\ \n",
    "\\textbf b_{i+1} &= \\textbf b_i - r\\nabla L_b \\\\ \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\nabla L_w$ and $\\nabla L_b$ are the gradients for updating the weights and biases respectively.\n",
    "\n",
    "Let us look at how to calculate the partial derivatives of w.r.t. to each parameter now, taking $w^{(1)}_{00}$ as an example:\n",
    "\n",
    "<center><img src=\"./img/Partial w.jpg\"/></center>\n",
    "\n",
    "We begin by looking at the equation $\\partial L/\\partial w^{(1)}_{00}$. From the above figure, we can see that the only value which is dependent on $w^{(1)}_{00}$ is $a^{(1)}_{0}$, which in turn depends on $z^{(1)}_{0}$. Using the chain rule, we can rewrite it as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial w^{(1)}_{00}} = \\frac{\\partial L}{\\partial a^{(1)}_{0}}\\frac{\\partial a^{(1)}_{0}}{\\partial w^{(1)}_{00}} = \\frac{\\partial L}{\\partial a^{(1)}_{0}}\\frac{\\partial a^{(1)}_{0}}{\\partial z^{(1)}_{0}} \\frac{\\partial z^{(1)}_{0}}{\\partial w^{(1)}_{00}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "Looking at the RHS, we begin with $\\partial z^{(1)}_{0}/\\partial w^{(1)}_{00}$, which is simply $a^{(0)}_0$, and $\\partial a^{(1)}_{0}/\\partial z^{(1)}_{0}$ depends on the activation function we use. However, $\\partial L/\\partial a^{(1)}_{0}$ is more complicated. \n",
    "\n",
    "\n",
    "We begin with the total derivative, $dL$. Note that $a^{(1)}_{0}$ is used in the calculation of all three nodes in $l = 2$, so we must take into account $a^{(2)}_{i} (i = 0, 1, 2)$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "dL &= \\frac{\\partial L}{\\partial a^{(2)}_{0}} da^{(2)}_{0} + \\frac{\\partial L}{\\partial a^{(2)}_{1}} da^{(2)}_{1}+\\frac{\\partial L}{\\partial a^{(2)}_{2}} da^{(2)}_{2}\\\\\n",
    "\\frac{\\partial L}{\\partial a^{(1)}_{0}} &= \\frac{\\partial L}{\\partial a^{(2)}_{0}} \\frac{\\partial a^{(2)}_{0}}{\\partial a^{(1)}_{0}} + \\frac{\\partial L}{\\partial a^{(2)}_{1}} \\frac{\\partial a^{(2)}_{1}}{\\partial a^{(1)}_{0}} + \\frac{\\partial L}{\\partial a^{(2)}_{2}} \\frac{\\partial a^{(2)}_{2}}{\\partial a^{(1)}_{0}} \\\\ \n",
    "&= \\sum^2_{i = 0} \\frac{\\partial L}{\\partial a^{(2)}_{i}} \\frac{\\partial a^{(2)}_{i}}{\\partial a^{(1)}_{0}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can see that this leads to another set of partial derivative $\\partial a^{(2)}_i /\\partial a^{(1)}_0$. We must be careful here, in that $a^{(2)}_i$, depending on what activation function we use, can depend on multiple $z^{(2)}$, such as in the case of Softmax, and so similar to how we calculated $dL$, we first find $da^{(2)}_i$ and then $\\partial a^{(2)}_i /\\partial a^{(1)}_0$, and we get:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial a^{(2)}_i}{\\partial a^{(1)}_0} = \\sum^2_{h = 0} \\frac{\\partial a^{(2)}_i}{\\partial z^{(2)}_h}\\frac{\\partial z^{(2)}_h}{\\partial a^{(1)}_0} =  \\sum^2_{h = 0} \\frac{\\partial a^{(2)}_i}{\\partial z^{(2)}_h}w^{(2)}_{h0} \\qquad \\text{for } i = 0, 1, 2\n",
    "$$\n",
    "\n",
    "and so finally, substituting back into the equation for $\\partial L/\\partial w^{(1)}_{00}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial w^{(1)}_{00}} = \\left\\{\\sum^2_{i = 0} \\left[\\sum^2_{h = 0} \\frac{\\partial a^{(2)}_i}{\\partial z^{(2)}_h}w^{(2)}_{h0}\\right]\\frac{\\partial L}{\\partial a^{(2)}_{i}}\\right\\}\\frac{\\partial a^{(1)}_{0}}{\\partial z^{(1)}_{0}} a^{(0)}_0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We see that the $\\partial L/\\partial a$ term reappears again, this time with an $l$ value one bigger than before. Like before, we substitute the corresponding sum:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial w^{(1)}_{00}} = \\left\\{\\sum^2_{i = 0} \\left[\\sum^2_{h = 0} \\frac{\\partial a^{(2)}_i}{\\partial z^{(2)}_h}w^{(2)}_{h0}\\right]\\left[\\sum^1_{m = 0}\\left(\\sum^1_{n = 0} \\frac{\\partial a^{(3)}_m}{\\partial z^{(3)}_n}w^{(3)}_{ni}\\right) \\frac{\\partial L}{\\partial a^{(3)}_{m}} \\right]\\right\\}\\frac{\\partial a^{(1)}_{0}}{\\partial z^{(1)}_{0}} a^{(0)}_0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "And once again we get the $\\partial L/\\partial a$ term again with $l$ value one bigger than before. However, this time, note that $\\partial L/\\partial a$ is on the $l = L_f=3$ final layer, and so $L$ is a direct function of $a^{(3)}_m$ and the recursive sum hits maximum depth and terminates. For $\\partial L/\\partial b^{(1)}_0$, we can show that it is simply:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial b^{(1)}_0} = \\left\\{\\sum^2_{i = 0} \\left[\\sum^2_{h = 0} \\frac{\\partial a^{(2)}_i}{\\partial z^{(2)}_h}w^{(2)}_{h0}\\right]\\left[\\sum^1_{m = 0}\\left(\\sum^1_{n = 0} \\frac{\\partial a^{(3)}_m}{\\partial z^{(3)}_n}w^{(3)}_{ni}\\right) \\frac{\\partial L}{\\partial a^{(3)}_{m}} \\right]\\right\\}\\frac{\\partial a^{(1)}_{0}}{\\partial z^{(1)}_{0}} = \\frac{1}{a^{(0)}_0}\\frac{\\partial L}{\\partial w^{(1)}_{00}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "With a way to update the parameters for each training cycle, we can now move on to creating the actual network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f03f73-56d2-4f8d-8540-f4c7bdfd8dbb",
   "metadata": {},
   "source": [
    "## DNN In Python\n",
    "\n",
    "### Progam Flow\n",
    "\n",
    "\n",
    "1. Model Initialisation\n",
    "\n",
    "The setup of the DNN begins with initialising the model architecture. In this step, we feed the model information about the number of inputs, the loss function, and also the hidden and output layers, each with information about the number of nodes and activation functions.\n",
    "\n",
    "2. Model Construction\n",
    "\n",
    "For every layer (input, hidden, output), corresponding number of node objects are created. The weights and biases are also initialised. \n",
    "\n",
    "3. Model Fitting\n",
    "\n",
    "    1. Training data and hyperparameters such as batch-size, learning rate, epoch number, validation percentage, optimisers etc are passed into the model.\n",
    "    2. Workers are setup for multiprocessing further on.\n",
    "    3. For each epoch, the model splits the dataset into batches. The model loops over each batch, sending each data instance into a different processor.\n",
    "       1. Within each worker, the input nodes are fed the input values of that data instance. Forward propagation is then carried out throughout the rest of the network.\n",
    "       2. Recursive sum is then calculated, back propogating throughout the network and gradient vector is calculated.\n",
    "       3. Worker ejects the gradient adds to a shared gradient vector\n",
    "    4. The average of all gradient vectors is calculated and used to update the parameters\n",
    "   \n",
    "### Storing parameters and node/layer information\n",
    "\n",
    "In order to store the weights and biases, two seperate 1-D numpy arrays are created. Taking the 3-3-3-2 architecture as an example, this means that the weight array is a 1-D array of size 24, and the bias array is a 1-D array of size 8.\n",
    "\n",
    "<center><img src=\"./img/param matrix.jpg\"/></center>\n",
    "\n",
    "To access the elements of the parameter arrays, we need an array of starting indices of each layer, such as \\[0, 0, 9, 18\\] for the weight array, and \\[0, 0, 3, 6\\] for the bias array. Notice that there is a filler \"0\" at the start of the array. This allows the index of the starting index array to match with the index of the layers. Practically, the filler can take on anything, such as a null value.\n",
    "\n",
    "To access $w^{(l)}_{jk}$, we simply index the $l$-th index of the starting index array, then add $j\\cdot N(l)$ and add $k$. E.g., to access $w^{(1)}_{12}$, first take the index-1 element of the starting index array \\[0, 0, 9, 18\\] which is $0$, then add to that $1\\cdot 3=3$ and finally add $k=2$, totally giving us the index-5 element of the weight array. To access $b^{(l)}_j$, take the $l$-th index of the starting index array then simply add $j$. To access $b^{(2)}_1$, take the index-2 element of \\[0, 0, 3, 6\\] which is $3$ then add $j=1$, and so totally giving us the index-4 of the bias array.\n",
    "\n",
    "With regards to the structure of the network, upon initialising the model, a list of \"Layer\" objects is created, each object having its own dictionary of nodes, whose values are \"Node\" objects.\n",
    "\n",
    "### Creating Layer and Node Classes\n",
    "\n",
    "We first begin by creating Layer and Node classes. \n",
    "\n",
    "The Layer class includes information about the number of nodes it has, its corresponding activation function, its position within the model, its mask (dropout, batch norm, L1/L2 regularisation, if any), as well as its \"node dictionary\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab64f338-91b9-4f6c-8530-947ed1b478e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:   \n",
    "    def __init__(self, N, activation_function = None):\n",
    "        self.N = N                                        #Number of nodes\n",
    "        self.activation_function = activation_function    #Corresponding activation function (if any)\n",
    "        self.L = None                                     #Position in network  \n",
    "        self.node_dict = {}                               #Node dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b242603a-d2d7-4135-a527-6a7737f11a96",
   "metadata": {},
   "source": [
    "The Node class includes information about its layer index, its position within the layer, the model which it belongs to and the number of nodes in its layer. It also includes a function which calculates the $z^{(l)}_j$ given the activations of the previous layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12363b55-40d7-47ba-8a38-838e9fed344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, l, j, model, layer_N):\n",
    "        self.l = l                                            #Layer index\n",
    "        self.j = j                                            #Position within layer\n",
    "        self.layer_N = layer_N                                #Total number of nodes in layer\n",
    "        self.a = None                                         #Activation value\n",
    "        self.z = None                                         #\"Pure\" value\n",
    "        self.loss = None                                      #Loss (limited to output node)\n",
    "        self.partial_loss = None                              #Partial derivative of loss w.r.t. to activation (limited to output node)\n",
    "        self.model = model                                    #Model which node belongs to\n",
    "        self.partial_a_list = np.zeros((self.layer_N,))       #List of partial derivative of activation w.r.t to all other z in layer\n",
    "    \n",
    "    #Calculate z values\n",
    "    def Calculate(self, previous_a):\n",
    "        weight_start_ind = self.model.weight_start_ind  #Assigns list of start indices for weight array\n",
    "        bias_start_ind = self.model.bias_start_ind      #Assigns list of start indices for bias array\n",
    "        prev_N = len(previous_a)                        #Gets number of nodes in previous layer\n",
    "        #Finds weights entering current node\n",
    "        weights_in = self.model.weight_matrix[int(weight_start_ind[self.l]+(self.j*prev_N)):int(weight_start_ind[self.l]+((self.j + 1)*prev_N))]\n",
    "        #Calculate and assigns z\n",
    "        self.z = float(np.dot(weights_in, previous_a) + self.model.bias_matrix[int(bias_start_ind[self.l]+self.j)])\n",
    "        return self.z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1f7119-8090-4112-8f74-1b05d6fa4aea",
   "metadata": {},
   "source": [
    "### Activation Functions, Loss Functions, and Optimisers\n",
    "\n",
    "We first define the structure of activation functions and optimisers. Activation functions in this program take in a layer object and calculate the activations of each node $\\partial a^{(l)}_i$ individually, as well as calculating a list of $\\partial a^{(l)}_i/\\partial z^{(l)}_h$ for all $z^{(l)}_h$ in the layer. For ReLU:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial a^{(l)}_i}{\\partial z^{(l)}_h} &= \n",
    "\\begin{cases}\n",
    "0, &i\\neq h\\\\\n",
    "\\frac{\\partial a^{(l)}_i}{\\partial z^{(l)}_i}, & i = h\n",
    "\\end{cases}\\\\\n",
    "\\frac{\\partial a^{(l)}_i}{\\partial z^{(l)}_i} &= \n",
    "\\begin{cases}\n",
    "0, & z^{(l)}_i <= 0\\\\\n",
    "1, & z^{(l)}_i > 0\\\\\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "For Softmax:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial a^{(l)}_i}{\\partial z^{(l)}_h} &= \n",
    "\\begin{cases}\n",
    "-a^{(l)}_i\\cdot a^{(l)}_h, &i\\neq h\\\\\n",
    "a^{(l)}_i\\cdot(1-a^{(l)}_i), & i = h\n",
    "\\end{cases}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0702a6d-95bf-4435-9614-5bd40ec85e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(layer):\n",
    "    for node in layer.node_dict.values():\n",
    "        z = node.z\n",
    "        #Activation\n",
    "        if z <= 0:\n",
    "            a = 0\n",
    "            da_dz = 0\n",
    "        else:\n",
    "            a = z\n",
    "            da_dz = 1\n",
    "        node.a = a\n",
    "\n",
    "        #da_dz\n",
    "        for i in range(layer.N):\n",
    "            if i == node.j:\n",
    "                node.partial_a_list[i] = da_dz\n",
    "            else:\n",
    "                node.partial_a_list[i] = 0\n",
    "\n",
    "def SoftMax(layer):\n",
    "    m = max([n.z for n in layer.node_dict.values()])\n",
    "    summ = sum([np.exp(node.z - m) for node in layer.node_dict.values()])\n",
    "    \n",
    "    #Activation \n",
    "    for node in layer.node_dict.values():\n",
    "        a = (np.exp(node.z - m)/summ).item()\n",
    "        node.a = a\n",
    "        \n",
    "    #da_dz\n",
    "    for node in layer.node_dict.values():\n",
    "        for i in range(layer.N):\n",
    "            if i == node.j:\n",
    "                node.partial_a_list[i] = node.a * (1 - node.a)\n",
    "            else:\n",
    "                node.partial_a_list[i] = -1 * node.a * list(layer.node_dict.values())[i].a\n",
    "\n",
    "def ArgMax(layer):\n",
    "    n_list = np.array([n.a for n in layer.node_dict.values()])\n",
    "    max_i = np.argmax(n_list)\n",
    "    for i in range(int(layer.N)):\n",
    "        if i == max_i:\n",
    "            n_list[i] = 1\n",
    "        else:\n",
    "            n_list[i] = 0\n",
    "        \n",
    "    return n_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ff5c93-d2a0-4eab-b41d-8705ae497a58",
   "metadata": {},
   "source": [
    "Loss functions take in the model object as well as the labelled data and returns the total loss calculated. For Residual Sum of Squares (RSS) and Categorical Cross-Entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4764c02-5b77-4d57-bd41-24d208c0857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSS(model, labelData):\n",
    "    total_loss = 0\n",
    "    for node in model.structure[-1].node_dict.values():\n",
    "        node.loss = (node.a - labelData[node.j])**2\n",
    "        node.partial_loss = 2*(node.a - labelData[node.j])\n",
    "        total_loss += node.loss\n",
    "    \n",
    "    return total_loss\n",
    "    \n",
    "def CrossEntropy(model, labelData):\n",
    "    layer_nodes = model.structure[-1].node_dict.values()\n",
    "    total_loss = sum([(-1*labelData[n.j]*np.log10(max(n.a, 10**(-200)))) for n in layer_nodes])\n",
    "    for node in layer_nodes:\n",
    "        node.loss = total_loss\n",
    "        node.partial_loss = -1*labelData[node.j]/(max(node.a, 10**(-200))*np.log(10))\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e2ecf-20de-4d55-bda8-0ec5a738dde9",
   "metadata": {},
   "source": [
    "Optimisers take in the weight and bias gradient array and returns a processed weight and bias gradient array. Apart from an input and output, optimisers also have running variables. Taking the Adam optimiser as an example:\n",
    "$$\n",
    "\\begin{align}\n",
    "v_{dW} &= \\beta_1v_{dW}+(1-\\beta_1)dW \\qquad      &&v_{db} = \\beta_1v_{db}+(1-\\beta_1)db \\\\\n",
    "s_{dW} &= \\beta_2s_{dW}+(1-\\beta_2)(dW)^2 \\qquad  &&s_{db} = \\beta_2s_{db}+(1-\\beta_2)(db)^2 \\\\ \\\\ \n",
    "V_{dW}^{corr} &= \\frac{v_{dW}}{(1-\\beta_1)^t} \\qquad  &&V_{db}^{corr} = \\frac{v_{db}}{(1-\\beta_1)^t} \\\\ \n",
    "S_{dW}^{corr} &= \\frac{s_{dW}}{(1-\\beta_1)^t} \\qquad  &&S_{db}^{corr} = \\frac{s_{db}}{(1-\\beta_1)^t} \\\\  \\\\ \n",
    "W_{i+1} &= W_{i} - r\\frac{V_{dW}^{corr}}{\\sqrt{S_{dW}^{corr}}+\\varepsilon} \\qquad &&b_{i+1} = b_{i} - r\\frac{V_{db}^{corr}}{\\sqrt{S_{db}^{corr}}+\\varepsilon}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef41a9-58e0-4fbe-8b87-c7c145b627e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def Initialise(self, w_size, b_size):\n",
    "        self.vw = np.zeros((w_size, ))\n",
    "        self.vb = np.zeros((b_size, ))\n",
    "        self.sw = np.zeros((w_size, ))\n",
    "        self.sb = np.zeros((b_size, ))\n",
    "        self.t = 1\n",
    "    \n",
    "    def Run(self, w_gradient, b_gradient, b1, b2, epsilon):\n",
    "        self.vw = b1*self.vw + (1-b1) * w_gradient\n",
    "        self.vb = b1*self.vb + (1-b1) * b_gradient\n",
    "        self.sw = b2*self.sw + (1-b2) * w_gradient ** 2\n",
    "        self.sb = b2*self.sb + (1-b2) * b_gradient ** 2\n",
    "\n",
    "        vw_corr = self.vw / (1-b1**self.t)\n",
    "        vb_corr = self.vb / (1-b1**self.t)\n",
    "        sw_corr = self.sw / (1-b2**self.t)\n",
    "        sb_corr = self.sb / (1-b2**self.t)\n",
    "\n",
    "        new_w_grad = vw_corr / (np.sqrt(sw_corr)+epsilon)\n",
    "        new_b_grad = vb_corr / (np.sqrt(sb_corr)+epsilon)\n",
    "        self.t += 1\n",
    "\n",
    "        return new_w_grad, new_b_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ebd49a-05c8-4081-9396-df5a423cd308",
   "metadata": {},
   "source": [
    "### Model Initialisation and Construction\n",
    "\n",
    "We can now begin initialising the model and constructing the structure/architecture of the network. Initialising the model requires telling it the number of input nodes, the loss function, as well as a list of Layer objects (defined above). \n",
    "\n",
    "Calling the `Construct` function on the model object builds the architecture of the network by creating the node dictionary of each layer and appending each layer object to the `self.structure` list. It also creates the parameter start index array, and initialises the weight and bias arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01360891-f29e-4be8-bd04-2e38cf27e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, inputN, loss_function, layers):\n",
    "        self.inputN = inputN                #Number of input nodes\n",
    "        self.loss_function = loss_function  #Loss function of the model\n",
    "        self.layers = layers                #List of hidden (HL) + output layers (OL)\n",
    "        self.L = len(self.layers)  |         #Number of HL + OL = index of OL\n",
    "        self.structure = []                 #List of layer objects\n",
    "        self.weight_matrix = np.array([])   #List of 1d array of weights \n",
    "        self.bias_matrix = np.array([])     #List of 1d array of biases\n",
    "\n",
    "    def Construct(self):\n",
    "        #Build model\n",
    "        \n",
    "        this_layer = {}\n",
    "        #Input layer (IL)\n",
    "            #Construct structure\n",
    "        input_layer_obj = Layer(self.inputN)\n",
    "        input_layer_obj.L = 0\n",
    "        for j in range(self.inputN):\n",
    "            this_layer[\"n0_\" + str(j)] = Node(0, j, self, self.inputN) #Assigns node objects\n",
    "        \n",
    "        input_layer_obj.node_dict = this_layer #Assigns node dictionary  \n",
    "        self.structure.append(input_layer_obj) #Appends layer object\n",
    "\n",
    "        #HL + OL\n",
    "            #Construct structure\n",
    "        for layer in self.layers:\n",
    "            this_layer = {}\n",
    "            this_layer_N = layer.N #number of nodes in current layer\n",
    "            layer.L = self.layers.index(layer) + 1\n",
    "            for j in range(this_layer_N):\n",
    "                this_layer[\"n\" + str(layer.L) + \"_\" + str(j)] = Node(layer.L, j, self, this_layer_N) #Assigns node object\n",
    "            layer.node_dict = this_layer       #Assigns node dictionary\n",
    "            self.structure.append(layer)       #Appends layer object\n",
    "\n",
    "        #Set up weight/bias start index array and calculate total number of weights/biases\n",
    "        self.weight_start_ind = np.zeros((self.L+1, )) #Start index array of weights\n",
    "        self.bias_start_ind = np.zeros((self.L+1, ))   #Start index array of biases\n",
    "        self.total_weight_n = 0                        #Total number of weights\n",
    "        self.total_bias_n = 0                          #Total number of biases\n",
    "        for l in self.structure[1:]:\n",
    "            self.weight_start_ind[l.L] = self.total_weight_n\n",
    "            self.total_weight_n += l.N * self.structure[l.L - 1].N\n",
    "            self.bias_start_ind[l.L] = self.total_bias_n\n",
    "            self.total_bias_n += l.N\n",
    "        \n",
    "        #Build weight (e.g. Kaiming Initialisation) and bias matrix \n",
    "        self.weight_matrix = np.random.normal(0, math.sqrt(2/self.inputN), (int(self.total_weight_n),))\n",
    "        self.bias_matrix = np.zeros((self.total_bias_n, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fc551e-acfc-4a57-9bd6-e56b64f9f082",
   "metadata": {},
   "source": [
    "### Model Fitting\n",
    "#### Forward Propagation\n",
    "\n",
    "In the forward propagation step, we first initialise all the input nodes with the input values of the training data instance. Then, for every subsequent layer, we call the `Calculate` function of each node object in the layer to calculate $z^{(l)}_j$. Then, for every layer, we apply the activation function to it and layer mask (if any). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815bcded-1aa0-4b16-b6df-f454ab36f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitialiseNodes(self, inputData, train = True):\n",
    "    for node in self.structure[0].node_dict.values(): #Initialise input node values\n",
    "        node.a = inputData[node.j].item()\n",
    "\n",
    "    for layer in self.structure[1:]:        #Initialise remaining node values\n",
    "        previous_layer_nodes = self.structure[layer.L - 1].node_dict.values()\n",
    "        previous_a = np.array([node.a for node in previous_layer_nodes]) #Search for a values of previous layer\n",
    "        for node in layer.node_dict.values():\n",
    "            node.Calculate(previous_a) #Calculate z values for current layer\n",
    "                        \n",
    "        layer.activation_function(layer) #Calculate a values for current layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae9396a-a8c9-4fd1-9a6b-4e5b23ed50e6",
   "metadata": {},
   "source": [
    "#### Backpropagation and Gradient Descent\n",
    "\n",
    "Before performing gradient descent, we calculate all the partial derivatives as part of the backpropagation step. First, the recursive sum $\\partial L/\\partial a^{(l)}_j$ is calculated using a recursive function. The sum for $\\partial a^{(l+1)}_i/\\partial a^{(l)}_j$ is calculated using the dot product of `partial_a_list` of the corresponding node $a^{(l+1)}_i$ with the weight array `w_list`. We also decorate the function with a cache decorator to allow for more optimal calculations when encountering previous function calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91570b-0bc7-425c-8206-601e2c58d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "@functools.cache\n",
    "def dLoss_da(self, l, j): \n",
    "    sum = 0\n",
    "    next_layer_N = self.structure[l+1].N\n",
    "    for i in range(next_layer_N):\n",
    "        next_node = self.structure[l+1].node_dict[f\"n{l+1}_{i}\"]\n",
    "        da_dz_list = next_node.partial_a_list\n",
    "        weight_ind = self.weight_start_ind\n",
    "        if l + 1 == self.L:  #Terminating condition; reach final layer\n",
    "            w_list = self.weight_matrix[int(weight_ind[-1]+j)::self.structure[l].N]\n",
    "            sum += np.dot(da_dz_list, w_list) * next_node.partial_loss\n",
    "        else:                #Recursive call\n",
    "            w_list = self.weight_matrix[int(weight_ind[l+1]+j):int(weight_ind[l+2]):self.structure[l].N]\n",
    "            sum += np.dot(da_dz_list, w_list) * self.dLoss_da(l+1, i)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e09f941-f1cb-48c7-be57-d02f590087c3",
   "metadata": {},
   "source": [
    "With the recurring sum defined, we can move on to calculate the final $\\partial L/\\partial w$ and $\\partial L/\\partial b$. Note that for calculating the partials for parameters in the output layer, the recurring sum is not needed as the loss function is a direction function of the parameters, so they must be handled separately. \n",
    "\n",
    "Then, to calculate the gradients, we first initialise two arrays $\\nabla L_w$ and $\\nabla L_b$ (`w_gradient`, `b_gradient`) where the partials will be collected. We then call the $\\partial L/\\partial w$ and $\\partial L/\\partial b$ functions for every parameter for all $l, j, k$, and add it to a weight/bias gradient array initialised earlier. These two arrays will then be used to update the weight and bias array of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d87364-7d7a-4063-bebd-c6dd54b4ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate dLoss_dwdb \n",
    "def dLoss_dwdb(self, l, j, k): \n",
    "    if l == self.L:  #Calculation for last layer weights/bias\n",
    "        past_a = self.structure[-2].node_dict[f\"n{l-1}_{k}\"].a\n",
    "        output_node = self.structure[-1].node_dict[f\"n{l}_{j}\"]\n",
    "        dL_da = output_node.partial_loss\n",
    "        da_dz = output_node.partial_a_list[output_node.j]\n",
    "    \n",
    "    else:            #General calculation for nth layer weights/bias\n",
    "        past_a = self.structure[l-1].node_dict[f\"n{l-1}_{k}\"].a\n",
    "        current_node = self.structure[l].node_dict[f\"n{l}_{j}\"]\n",
    "        da_dz = current_node.partial_a_list[current_node.j]\n",
    "        dL_da = self.dLoss_da(l, j)\n",
    "\n",
    "    partial_w = dL_da * da_dz * past_a\n",
    "    partial_b = dL_da * da_dz\n",
    "    return partial_w, partial_b\n",
    "\n",
    "#Calculate partials for all parameters and append them to gradient array \n",
    "def Gradient(self):\n",
    "    w_gradient = np.zeros((self.total_weight_n, ))\n",
    "    b_gradient = np.zeros((self.total_bias_n, ))\n",
    "\n",
    "    for layer in self.structure[1:]:\n",
    "        prev_layer_N = self.structure[layer.L - 1].N\n",
    "        weight_start_index = self.weight_start_ind[layer.L]\n",
    "        bias_start_index = self.bias_start_ind[layer.L]\n",
    "        for n in layer.node_dict.values():\n",
    "            for k in range(prev_layer_N):\n",
    "                dLoss_wb = self.dLoss_dwdb(layer.L, n.j, k)\n",
    "                w_gradient[int(weight_start_index + n.j*prev_layer_N + k)] = dLoss_wb[0]\n",
    "                \n",
    "            b_gradient[int(bias_start_index + n.j)] = dLoss_wb[1]\n",
    "\n",
    "    return (w_gradient, b_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12670fb3-43f1-4950-9b34-b93102c780ab",
   "metadata": {},
   "source": [
    "#### Multiprocessing workers\n",
    "\n",
    "To optimise the backpropogation process, multiprocessing is used to calculate forward and back propagations of different data instances in a batch at the same time. Each worker has three queues associated with it. One is an instruction queue unique to the worker, and one input queue and one output queue, both shared among all workers:\n",
    "1. At the start of every batch, a \"start\" command is fed to each instruction queue to tell the $n$ workers to begin\n",
    "2. All data instances of the batch is fed into the communal input queue, then $n$ number of \"wait\" commands is fed to communal input queue\n",
    "    1. Workers grab data instances and completes forward propagation to find predicted output and loss, and compute gradient\n",
    "    2. Spit out calculations into communal output queue\n",
    "    3. Workers repeat process until all data instances are siphoned. When worker siphons \"wait\" command, worker waits until \"start\" command is fed again\n",
    "3. Grab all items from communal output queue and update losses and gradients\n",
    "\n",
    "<center><img src=\"./img/Worker.jpg\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc829ecf-4adc-406a-ad04-a68b26a03bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worker process\n",
    "def TaskWorker(in_q, out_q, worker_id, signal):\n",
    "    wait = True\n",
    "    while True:\n",
    "        if wait == True:\n",
    "            if signal.empty():       #If instruction queue is empty, keep waiting\n",
    "                continue\n",
    "            else:\n",
    "                model = signal.get() #Else, fetch model and stop waiting\n",
    "                wait = False\n",
    "        else:                        \n",
    "            feed = in_q.get()        #Siphon items from communal input queue\n",
    "            if feed == \"wait\":       #If \"wait\" command, tell output communal queue \"this worker is waiting\" and wait\n",
    "                out_q.put(str(worker_id))\n",
    "                wait = True\n",
    "            else:\n",
    "                inputData = feed[1]                            #Initialise input values \n",
    "                if feed[0] == \"calculate\":\n",
    "                    train = True\n",
    "                else:\n",
    "                    train = False\n",
    "                model.InitialiseNodes(inputData, train)\n",
    "                labelData = feed[2]                            #Initialise output labels\n",
    "                #Calculate loss\n",
    "                loss = model.loss_function(model, labelData)\n",
    "\n",
    "                #Calculate predictions\n",
    "                if type(model.threshold) == float:\n",
    "                    predict = np.array([(1.0 if n.a >= 0.7 else 0.0) for n in model.structure[-1].node_dict.values()])\n",
    "                elif model.threshold == ArgMax:\n",
    "                    return_layer = ArgMax(model.structure[-1])\n",
    "                    predict = return_layer\n",
    "                else:\n",
    "                    predict = np.array([n.a for n in model.structure[-1].node_dict.values()])\n",
    "\n",
    "                vec = np.sum(predict * labelData)\n",
    "                if vec == 1:\n",
    "                    correct = 1\n",
    "                else:\n",
    "                    correct = 0\n",
    "                \n",
    "                if feed[0] == \"calculate\":\n",
    "                    #Calculate gradients of current iteration\n",
    "                    gradient_matrix = model.Gradient()\n",
    "\n",
    "                    #Clears cache memory to prepare for next data sample\n",
    "                    model.dLoss_da.cache_clear()\n",
    "\n",
    "                    #Submit calculations to output queue\n",
    "                    out_q.put((gradient_matrix[0], gradient_matrix[1], loss, correct,))  \n",
    "\n",
    "                else: \n",
    "                    #Submit calculations to output queue\n",
    "                    out_q.put((loss, correct,))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c54d7-0726-45f9-aadb-a5a0941ceec1",
   "metadata": {},
   "source": [
    "#### Fitting Function\n",
    "\n",
    "In the \"Model\" class, we define a main parent function `Fit`, which calls the other calculation functions defined above. It first begins with splitting up the passed data set into a training and validation set, and initialises any optimisers (e.g. Adam, RMSProp) as well as the multiprocessing workers and the queues needed. The function then loops through every epoch. Within each epoch, the batches are split, and a \"start\" command is passed to each worker. For every instance in the batch, it is passed through to the input queue, followed by a \"wait\" command. The gradients for each instance is then siphoned out of the output queue and added to a running total gradient array, which after all instances are done calculating, the average gradient is calculated and used to update the parameters. \n",
    "\n",
    "It is then here the workers are restarted, and used to forward propagate the network using the various inputs in the validation set to calculate validation loss and accuracy. The calculations for the current batch is then over, and the process repeats for the next batch. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96865fd4-03dc-410e-9442-7d75487212df",
   "metadata": {},
   "source": [
    "```python\n",
    "def Fit(self, xdata_train, ydata_train, n_batches, lr, max_epoch, validation, optimiser = None, optimiser_params = None, threshold = None):\n",
    "\n",
    "    self.threshold = threshold\n",
    "    x_valid = xdata_train.sample(frac = validation)\n",
    "    y_valid = ydata_train.loc[x_valid.index]\n",
    "    x_train = xdata_train.drop(x_valid.index)\n",
    "    y_train = ydata_train.drop(y_valid.index)\n",
    "    n_instance_valid = x_valid.shape[0]\n",
    "\n",
    "    x_valid = x_valid.to_numpy()\n",
    "    y_valid = y_valid.to_numpy()\n",
    "\n",
    "\n",
    "    #Split training data into batches and validation\n",
    "    x_batches, y_batches = np.array_split(x_train.to_numpy(), n_batches), np.array_split(y_train.to_numpy(), n_batches) \n",
    "\n",
    "    if optimiser != None:\n",
    "        optimiser.Initialise(self.total_weight_n, self.total_bias_n)\n",
    "\n",
    "    # Create multiprocessing workers\n",
    "    print(\"Creating workers...\")\n",
    "    n_workers = 8\n",
    "    in_q = mp.Queue()\n",
    "    out_q = mp.Queue()\n",
    "    wait_signal = [mp.Queue() for i in range(n_workers)]\n",
    "\n",
    "    processes = []\n",
    "    for i in range(n_workers):\n",
    "        p = mp.Process(target = TaskWorker, args = (in_q, out_q, i, wait_signal[i],))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    print(\"Workers created\")\n",
    "\n",
    "    epoch_loss_history = []\n",
    "    batch_loss_history = []\n",
    "    batch_accuracy_history = []\n",
    "    val_loss_history = []\n",
    "    val_accuracy = []\n",
    "    n_runs = 0\n",
    "    cur_epoch = 1\n",
    "    stop = False\n",
    "    while cur_epoch <= max_epoch:\n",
    "        if stop == True:\n",
    "            break\n",
    "        \n",
    "        epoch_loss = 0\n",
    "\n",
    "        batch_no = 1\n",
    "        for batch_ind in range(n_batches):\n",
    "\n",
    "            batch_timer = Stopwatch()\n",
    "            batch_timer.start()\n",
    "            batch_loss = 0\n",
    "\n",
    "            w_gradients = np.zeros((self.total_weight_n, )) #Initialise batch-wise gradients\n",
    "            b_gradients = np.zeros((self.total_bias_n, ))\n",
    "\n",
    "            x_batch = x_batches[batch_ind]\n",
    "            y_batch = y_batches[batch_ind]\n",
    "            n_instances = np.shape(x_batch)[0]\n",
    "\n",
    "            # Signal workers to start collecting\n",
    "            for i in range(n_workers):\n",
    "                wait_signal[i].put(self)\n",
    "            \n",
    "\n",
    "            # Feeding data\n",
    "            for row in range(n_instances):\n",
    "                package = (\"calculate\", x_batch[row], y_batch[row],)\n",
    "                in_q.put(package)\n",
    "            \n",
    "            #Feeding wait command\n",
    "            for p in range(n_workers):\n",
    "                in_q.put(\"wait\")\n",
    "\n",
    "            print(f\"Batch {batch_no} of {n_batches} | Siphoning items\", end=\"\\r\", flush = True)\n",
    "            terminated = 0\n",
    "            batch_correct = 0\n",
    "            while terminated < n_workers:\n",
    "                item = out_q.get()\n",
    "                if type(item) == str:\n",
    "                    # processes[int(item)].terminate()\n",
    "                    # processes[int(item)].join() \n",
    "                    terminated += 1   \n",
    "                    # print(\"Worker \" + item + \" waiting\")\n",
    "                else:\n",
    "                    w_gradients += item[0]\n",
    "                    b_gradients += item[1]\n",
    "                    batch_loss += item[2]\n",
    "                    batch_correct += item[3]\n",
    "                \n",
    "            #Calculate average batch-wise gradients and update weights/biases\n",
    "            w_gradients /= n_instances #Average weight calculation\n",
    "            b_gradients /= n_instances #Average bias calculation\n",
    "\n",
    "            #Run optimiser\n",
    "            if optimiser != None:\n",
    "                w_gradients, b_gradients = optimiser.Run(w_gradients, b_gradients, *optimiser_params)\n",
    "\n",
    "            #Update weight and bias matrix\n",
    "            self.weight_matrix -= lr * w_gradients \n",
    "            self.bias_matrix -= lr * b_gradients\n",
    "\n",
    "            batch_loss /= n_instances\n",
    "            batch_timer.stop()\n",
    "\n",
    "            batch_loss_history.append(batch_loss)\n",
    "            \n",
    "            n_runs += 1\n",
    "            epoch_loss += batch_loss\n",
    "\n",
    "            #Run validation\n",
    "            print(f\"Batch {batch_no} of {n_batches} | Calculating validation\", end=\"\\r\", flush = True)\n",
    "\n",
    "            # Signal workers to start collecting\n",
    "            for i in range(n_workers):\n",
    "                wait_signal[i].put(self)\n",
    "\n",
    "            # Feeding validation data\n",
    "            for row in range(n_instance_valid):\n",
    "                package = (\"validate\", x_valid[row], y_valid[row],)\n",
    "                in_q.put(package)\n",
    "            \n",
    "            #Feeding wait command\n",
    "            for p in range(n_workers):\n",
    "                in_q.put(\"wait\")\n",
    "\n",
    "            terminated = 0\n",
    "            correct = 0\n",
    "            val_loss = 0\n",
    "            while terminated < n_workers:\n",
    "                item = out_q.get()\n",
    "                if type(item) == str:\n",
    "                    terminated += 1   \n",
    "                else:\n",
    "                    val_loss += item[0]\n",
    "                    correct += item[1]\n",
    "                                    \n",
    "            acc = correct / n_instance_valid\n",
    "            val_accuracy.append(acc)\n",
    "            val_loss /= n_instance_valid\n",
    "\n",
    "            batch_acc = batch_correct / n_instances\n",
    "            val_loss_history.append(val_loss)\n",
    "            batch_accuracy_history.append(batch_acc)\n",
    "            \n",
    "            print(f\"Batch {batch_no} of {n_batches} | Time elapsed: {batch_timer.elapsed:.2f} s | Batch Loss: {batch_loss:.5f} | Batch Accuracy: {batch_acc:.5f} | Validation Loss: {val_loss:.5f} | Validation Accuracy: {acc:.5f}\")\n",
    "            \n",
    "            batch_no += 1\n",
    "\n",
    "        epoch_loss /= batch_no \n",
    "        print(f\"\\nEpoch {cur_epoch} of {max_epoch}. Loss: {epoch_loss}.\")\n",
    "        print(\"-\"*90)\n",
    "        epoch_loss_history.append(epoch_loss)\n",
    "\n",
    "        cur_epoch += 1\n",
    "\n",
    "    return [epoch_loss_history, self.weight_matrix, self.bias_matrix, cur_epoch, n_runs, batch_loss_history, batch_accuracy_history, val_loss_history, val_accuracy]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67903791-f647-4f7f-b66c-859369129699",
   "metadata": {},
   "source": [
    "#### Test Set Prediction\n",
    "\n",
    "The final function of the `Model` class is the `Predict` function, which takes in a test set and calculates the number of correct predictions and loss of the test set using the trained model. For every instance in the test set, it runs the forward propagation and calculates the output layer activations, which then depending on the threshold (e.g. a constant value, ArgMax etc) is processed into a one-hot encoded answer or left as-is if no threshold is given. Comparing it to the label will then return whether the prediction was correct or not. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50861303-2c46-4669-86ea-f79c9391fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(self, test_input, test_label, threshold = None):\n",
    "\n",
    "    n_correct = 0\n",
    "    length = np.shape(test_input)[0]\n",
    "    avg_loss = 0\n",
    "    for i in range(length):\n",
    "        instance_features = test_input[i]\n",
    "        instance_label = test_label[i]\n",
    "\n",
    "        self.InitialiseNodes(instance_features, train = False)\n",
    "        avg_loss += self.loss_function(self, instance_label)\n",
    "\n",
    "        if type(threshold) == float:\n",
    "            predict = np.array([(1.0 if n.a >= 0.7 else 0.0) for n in self.structure[-1].node_dict.values()])\n",
    "        elif threshold == ArgMax:\n",
    "            return_layer = ArgMax(self.structure[-1])\n",
    "            predict = return_layer\n",
    "        else:\n",
    "            predict = np.array([n.a for n in self.structure[-1].node_dict.values()])\n",
    "\n",
    "        vec = np.sum(predict * instance_label)\n",
    "        \n",
    "        if vec == 1:\n",
    "            n_correct += 1\n",
    "    \n",
    "    return avg_loss / length, n_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e104aae9-cb55-4519-876b-c386a6bc073d",
   "metadata": {},
   "source": [
    "## Image Recognition with MNIST Dataset\n",
    "\n",
    "### Data Preparation \n",
    "\n",
    "The MNIST training and testing dataset comes from [MNIST in CSV](https://www.kaggle.com/datasets/oddrationale/mnist-in-csv) by Dariel Dato-on. Using Excel, the labels are one-hot encoded: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bfa0043-9f96-40e5-801c-47d0db523a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  794 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  28x19  28x20  28x21  28x22  28x23  \\\n",
       "0  0  0  0  0  0  1  0  0  0  0  ...      0      0      0      0      0   \n",
       "1  1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "2  0  0  0  0  1  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "3  0  1  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "4  0  0  0  0  0  0  0  0  0  1  ...      0      0      0      0      0   \n",
       "\n",
       "   28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0  \n",
       "1      0      0      0      0      0  \n",
       "2      0      0      0      0      0  \n",
       "3      0      0      0      0      0  \n",
       "4      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 794 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"mnist_train.csv\")\n",
    "test_data = pd.read_csv(\"mnist_test.csv\") \n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be28016-0819-48c4-9780-dcb42c4b305d",
   "metadata": {},
   "source": [
    "We demarcate the index where the features begin and the labels end. Before passing the data into the model, we first normalise the features/inputs of the dataset:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{x_i} = \\frac{x_i-\\mu}{\\sigma}\n",
    "\\end{align}\n",
    "$$\n",
    "where each value is subtracted by the mean of the corresponding column, and divided by the standard deviation of the same column. This ensures the emphasis/importance of each feature is not biased purely because of the magnitude of values, and emphasies the relatinship between each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9654cd-d5de-446b-a0dc-a52defb319dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata_start_ind = 10                                #Features start at index-10 of the dataframe\n",
    "xdata_train = train_data.iloc[:, xdata_start_ind:]\n",
    "ydata_train = train_data.iloc[:, :xdata_start_ind] \n",
    "\n",
    "mu = xdata_train.mean(axis = 0)\n",
    "sd = xdata_train.std(axis = 0)    #Mean and sd of each column of data\n",
    "sd.replace(0, 1, inplace = True)  #We replace all columns with s.d. = 0 with 1 to avoid divide-by-zero error when normalising \n",
    "xdata_train = (xdata_train.sub(mu, axis = 1)).div(sd, axis = 1) #Normalise each column of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d81f11-8010-4614-aed8-2f2872be58a2",
   "metadata": {},
   "source": [
    "### Model Initialisation \n",
    "\n",
    "#### Parameter Initialisation\n",
    "\n",
    "We use a model architecture of 784-128-64-10 (Input, ReLU, ReLU, Softmax) to demonstrate the network. After testing various architectures, this is the one which yielded the highest test accuracy.\n",
    "\n",
    "Using this architecture, two hidden layers use ReLU as their activation function. As ReLU is unbounded for positive values, by the time we reach the output layer, the variance of the output $z^{(L_f)}_j$ is extremely large, causing the Softmax layer to output only 0 and 1s, leading to a 0 gradient and so no learning can be performed. \n",
    "\n",
    "For example, imagine the $z^{(L_f)}_j$ to have the values \\[-1000, 20, 2000, 1400, -600, 200, 900, -700, -10, 1000\\]. If we perform Softmax on these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133c4e39-4dd9-4539-af6b-884dd9d32cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+000 0.00000000e+000 1.00000000e+000 2.65039655e-261\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([-1000, 20, 2000, 1400, -600, 200, 900, -700, -10, 1000])\n",
    "\n",
    "m = max(a.tolist())\n",
    "summ = sum([np.exp(k - m) for k in a])\n",
    "\n",
    "b = np.exp(a-m) / summ\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d895a352-6380-4efc-b7db-c746194af286",
   "metadata": {},
   "source": [
    "We can see that we only get 0 and 1s. If we take a look at the $\\frac{\\partial a^{(l)}_i}{\\partial z^{(l)}_h}$ for the Softmax function:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial a^{(l)}_i}{\\partial z^{(l)}_h} &= \n",
    "\\begin{cases}\n",
    "-a^{(l)}_i\\cdot a^{(l)}_h, &i\\neq h\\\\\n",
    "a^{(l)}_i\\cdot(1-a^{(l)}_i), & i = h\n",
    "\\end{cases}\\\\ \n",
    "&= 0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "as $a^{(l)}_i = 0$ or $1$ for all $i$ and so $\\nabla L=0$, thus no learning will occur. Hence, we have to choose how we initialise our weights. The most common method when using ReLU is to use He or Kaiming Initialisation, where the weights are normally distributed with a mean of $0$ and a variance of $\\sqrt{2/N(0)}$ (where $N(0)$ is the number of input nodes).\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "W\\sim \\mathcal{N}\\left(0,\\frac{2}{N(0)}\\right) \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Hyperparameters and Model Training\n",
    "The hyperparameters of the model include the number of inputs, number of training epochs, parameters for optimisers (if any), batch size (if performing mini-batch gradient descent), and learning rate. The code to construct and run the model is included below only for display, as jupyter does not support multiprocessing. The .py files are included in the parent folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae950561-0814-4860-8adf-3abf7311612b",
   "metadata": {},
   "source": [
    "```python\n",
    "#Hyper parameters\n",
    "inputN = 784          #Number of inputs    \n",
    "max_epoch = 5         #Training epochs\n",
    "b1 = 0.9     \n",
    "b2 = 0.999\n",
    "epsilon = 10**(-8)    #Optimiser parameters (Adam)\n",
    "batch_size = 128       #Mini-batch size\n",
    "lr = 0.001            #Learning rate\n",
    "valid_percent = 0.2   #Percentage of data to use for validiation\n",
    "\n",
    "\n",
    "model = Model(inputN, CrossEntropy, [Layer(128, ReLU),\n",
    "                                     Layer(64, ReLU),\n",
    "                                     Layer(10, SoftMax)])     #Initialise architecture of network\n",
    "model.Construct()   #Construct the network\n",
    "\n",
    "batch_num = int(np.floor(xdata_train.shape[0]/batch_size))\n",
    "\n",
    "#Train the model\n",
    "stopwatch_0 = Stopwatch()\n",
    "stopwatch_0.start()\n",
    "fitted_return = model.Fit(xdata_train, ydata_train, batch_num, lr, max_epoch, valid_percent, Adam(), (b1, b2, epsilon,), threshold=ArgMax)\n",
    "stopwatch_0.stop()\n",
    "print(\"Total training time: \", stopwatch_0.elapsed, \" seconds.\")\n",
    "\n",
    "#Plotting loss and accuracy graphs\n",
    "history = fitted_return[0]\n",
    "n_epochs = fitted_return[3]\n",
    "n_runs = fitted_return[4]\n",
    "batch_loss_history = fitted_return[5]\n",
    "batch_acc_history = fitted_return[6]\n",
    "val_loss_history = fitted_return[7]\n",
    "val_acc_history = fitted_return[8]\n",
    "\n",
    "ax1 = plt.subplot(411)\n",
    "ax1.plot(np.arange(1, n_epochs), np.array(history))\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "ax2 = plt.subplot(412)\n",
    "ax2.plot(np.arange(1, n_runs+1), np.array(batch_acc_history), label = \"Batch Accuracy\")\n",
    "ax2.plot(np.arange(1, n_runs+1), np.array(batch_loss_history), label = \"Batch Loss\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.legend(loc=\"center right\")\n",
    "plt.tick_params('x', labelbottom=False)\n",
    "\n",
    "ax3 = plt.subplot(413, sharex = ax2)\n",
    "ax3.plot(np.arange(1, n_runs+1), np.array(val_acc_history), label = \"Validation Accuracy\")\n",
    "ax3.plot(np.arange(1, n_runs+1), np.array(val_loss_history), label = \"Validation Loss\")\n",
    "ax3.set_ylabel(\"Loss\")\n",
    "ax3.legend(loc=\"center right\")\n",
    "plt.tick_params('x', labelbottom=False)\n",
    "\n",
    "ax4 = plt.subplot(414, sharex = ax2)\n",
    "ax4.plot(np.arange(1, n_runs+1), np.array(val_acc_history), label = \"Validation Accuracy\")\n",
    "ax4.plot(np.arange(1, n_runs+1), np.array(batch_acc_history), label = \"Batch Accuracy\")\n",
    "ax4.set_ylabel(\"Loss\")\n",
    "ax4.set_xlabel(\"-th Calculation\")\n",
    "ax4.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax4.legend(loc=\"center right\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3697b3d8-ed99-4e9d-bbfb-de036f69dd14",
   "metadata": {},
   "source": [
    "Below, a screenshot of the training process and test prediction results are shown, ran in Windows command prompt:\n",
    "\n",
    "<center><img src=\"./img/running.png\"/></center>\n",
    "<center><img src=\"./img/results.png\"/></center>\n",
    "\n",
    "The test predictions returned with a good accuracy, of 96.46% accuracy. \n",
    "\n",
    "Below, we plotted the epoch loss, as well as validation and training losses/accuracy per batch. The y-axis represents the accuracy/loss values. \n",
    "\n",
    "<center><img src=\"./img/Loss.png\"/></center>\n",
    "\n",
    "Surprisingly, there are no obvious signs of overfitting to the training data. Even without dropout, regularisation, or batch normalisation techniques applied, the validation and batch accuracy curves are pretty much mirrored, apart from the slight volatility of the batch accuracy curve. This may be due to the vast amount of training data we had, and so the model was able to generalise relatively well. \n",
    "\n",
    "## Conclusion and Ending Remarks\n",
    "\n",
    "This personal project was a way for me to familiarise myself with the fundamentals of machine learning in the context of a multi-layer perception. By going through the mathematics of forward and backpropagation, gradient descent, as well as how different activation functions work and the concept of optimisers, it allowed me to really grasp the idea of how these processes worked together to \"train\" and allow the machine to \"learn\". By getting hands-on with Python and implementing the mathematics, I could better understand and appreciate the steps it took to train a model, especially how mini-batch gradient descent reduced training times by moving down the slope more frequently, albeit less accurately at times. This project was also very much object-oriented, which is something I have seldom worked with before. By creating all these `Node` and `Layer` objects and the main `Model` class, I have become much more comfortable with OOP, and understand its benefits.\n",
    "\n",
    "There are many versions of the model and slight tweaks which did not make it to this final Jupyter Notebook, so I would like to document some of the major changes I made here, to serve as a log of the things I have learnt:\n",
    "\n",
    "##### Backpropagation mistake\n",
    "\n",
    "Early on, when first going through the mathematics of backpropagation, I assumed ReLU activations for every hidden layer due to the simplicity of the ReLU function, where its derivatives are either 1 or 0, based on the $z^{(l)}_j$ value of the corresponding node, and so the backpropagations were carried out with the following equation:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial a^{(l+1)}_i}{\\partial a^{(l)}_j} = \\frac{\\partial a^{(l+1)}_i}{\\partial z^{(l+1)}_i}\\frac{\\partial z^{(l+1)}_i}{\\partial a^{(l)}_j} =  \\frac{\\partial a^{(l+1)}_i}{\\partial z^{(l+1)}_i}w^{(l+1)}_{ij} \\qquad\n",
    "$$\n",
    "\n",
    "This is true for ReLU, as the activation only depends on its own node. However, when introducing Softmax, where its activation depends on the $z$ of all other nodes in the layer, the equation above is incorrect, and so was replaced with the correct version:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial a^{(l+1)}_i}{\\partial a^{(l)}_j} = \\sum^{N(l+1)-1}_{h = 0} \\frac{\\partial a^{(l+1)}_i}{\\partial z^{(l+1)}_h}\\frac{\\partial z^{(l+1)}_h}{\\partial a^{(l)}_j} =  \\sum^{N(l+1)-1}_{h = 0} \\frac{\\partial a^{(l+1)}_i}{\\partial z^{(l+1)}_h}w^{(l+1)}_{hj}\n",
    "$$\n",
    "\n",
    "##### Numerical stability of Softmax\n",
    "The normal softmax functions include taking the natural exponent of the $z$ values. When combined with ReLU activation functions in the previous layers, I ran into an overflow error. This is due to the fact that the Softmax function is attempting to take the natural exponent of numbers in the order of magnitude $10^3$. To counter this, a numerically stable version of Softmax is applied, where all the exponents ($z$ values) of the layer had $m=\\max {\\textbf z}$ subtracted from them:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Softmax}(z^{(l)}_i) = \\frac{e^{-m}}{e^{-m}} \\cdot \\frac{e^{z^{(l)}_i}}{\\sum_{k=0}^{N(l)-1}e^{z^{(l)}_k}} = \\frac{e^{z^{(l)}_i-m}}{\\sum_{k=0}^{N(l)-1}e^{z^{(l)}_k-m}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This ensured that the exponents will not be so large such that python will not be able to handle the value.\n",
    "\n",
    "##### Parameter Initialisation\n",
    "At first, the weights were randomly normalised between -1 and 1. However, this soon proved to be a poor choice of initialisation as the two ReLU layers quickly caused the activations to skyrocket, which rendered the Softmax layer useless, as the variance of the values were so large the Softmax function outputted 0 and 1 instead of softer percentages, essentially reducing it to an ArgMax function. However, for ReLU layers, a well-documented initialisation method exists, which is the He or Kaiming Initialisation, as mentioned in the notebook. This allowed the model to train with more controlled values, and the Softmax was able to convert the final output layer's activations into a much more \"softer\" set of values. \n",
    "\n",
    "##### Iterating through a pandas dataframe\n",
    "In one of the earliest versions of the model, to calculate the gradient for each data instance in a mini-batch, the `Fit` function iterated through each row of the training data pandas dataframe using the `pandas.DataFrame.iterrows()` function. However, after profiling the code, it seemed that a majority of the runtime was spent executing the `iterrows()` function. Hence, the `Fit` function was changed such that the training dataframe was converted into a numpy array as soon as the `Fit` function was called. Instead of iterating each row of the dataframe, the mini-batch was looped over using a index-based for-loop on a numpy array. This halved the runtime.\n",
    "\n",
    "##### Vectorising\n",
    "Another optimisation made was converting lists into 1-D numpy arrays. In first version of the model, the weights were stored as a list, where each element of the list was a 2-D numpy array of shape $(N(l), N(l-1))$. This made it easy to index the parameters, as the indexes were the same as the mathematical indices. However, by flattening the parameters into a 1-D numpy array, it saved a lot of processing time to index the elements, but also made calculations with the weights much more optimised. \n",
    "\n",
    "##### Multiprocessing \n",
    "The first versions of multiprocessing included creating new workers every training sample in the batch, and shutting down the workers after each sample in the batch. However, this proved to be extremely slow, as creating the overheads and shutting down the workers took a significant amount of time. Hence, the final version has the workers set up at the start of the entire training session, and only shuts down after the model has finished training fully. \n",
    "\n",
    "As the worker is designed to constantly siphon data from the feed-in/input queue and a while loop is used to siphon items out of the output queue, the workers need to be able to stop grabbing items from the input queue and output a \"finished\" signal to the output queue so that the output queue's while loop knows when to break. This inspired the \"waiting\" mechanism. Essentially, when the worker is fed a \"wait\" signal, it stops siphoning from the input queue, and spits a \"finished\" message to the output queue. When all workers are \"finished\" for the batch, the output queue while loop breaks, and the gradient descent process can continue.\n",
    "\n",
    "However, an issue still remains is that the `.get()` method of the output queue is considerably slow, around 0.01 seconds for each item if not more. For a batch with 128 samples, siphoning items from the multiprocessing queue will take 1.28 seconds. From the console alone, we can see that this accounts for around 85% of the training time for each batch, which is not ideal. However, it is still astronomically faster than calculating each sample one by one in the case of monoprocessing.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
